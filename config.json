{
    "batch_size": 64,
    "block_size": 256,
    "dropout": 0.2,
    "learning_rate": 0.0006,
    "max_iters": 32000,
    "n_embd": 512,
    "n_head": 4,
    "n_layer": 4,
    "vocab_size": 41
}